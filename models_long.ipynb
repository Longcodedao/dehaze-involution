{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "from models.involution import * \n",
    "from models.unet import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** 0.5\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalize across the channel dimension\n",
    "        return F.normalize(x, dim=1) * self.scale * self.gamma.view(1, -1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck_Long(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, inv_kernel = 7):\n",
    "        super(BottleNeck_Long, self).__init__()\n",
    "        self.invblock = nn.Sequential(\n",
    "            Involution_CUDA(in_channels, kernel_size = inv_kernel, stride = 1),\n",
    "            RMSNorm(in_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels,\n",
    "                      out_channels = out_channels,\n",
    "                      kernel_size = 1,\n",
    "                      stride = 1,\n",
    "                      padding = 0,\n",
    "                      bias = False),\n",
    "            RMSNorm(out_channels),\n",
    "        )   \n",
    "\n",
    "        self.mapping=nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels,\n",
    "                      out_channels = out_channels,\n",
    "                      kernel_size = 1,\n",
    "                      padding = 0),\n",
    "            RMSNorm(out_channels))\n",
    "        \n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.invblock(x)\n",
    "        x1 = self.conv_block(x1)\n",
    "\n",
    "        if x.shape[1] != x1.shape[1]:\n",
    "            x = self.mapping(x)\n",
    "\n",
    "        return self.gelu(x1 + x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET_Long(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 1, \n",
    "                 features = [64, 128, 256, 512], device = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "\n",
    "        self.warmup_conv = nn.Conv2d(in_channels = in_channels, \n",
    "                                     out_channels = features[0],\n",
    "                                     kernel_size = 3,\n",
    "                                     padding = 1)\n",
    "        \n",
    "        self.final_layer = nn.Conv2d(in_channels = features[0],\n",
    "                                     out_channels = out_channels,\n",
    "                                     kernel_size = 1)\n",
    "        \n",
    "        self.bottle_neck = BottleNeck_Long(in_channels = features[-1],\n",
    "                                      out_channels = features[-1] * 2)\n",
    "\n",
    "        in_channels_temp = features[0]\n",
    "\n",
    "        # down\n",
    "        for i in range(len(features)):\n",
    "            in_channels_temp = features[i]\n",
    "            self.downs.append(\n",
    "                BottleNeck_Long(in_channels_temp,\n",
    "                           out_channels = in_channels_temp))\n",
    "            \n",
    "            if i < len(features) - 1:\n",
    "                # Instead of using AvgPool2D\n",
    "                self.downs.append(nn.Conv2d(in_channels = in_channels_temp,\n",
    "                                        out_channels = features[i + 1],\n",
    "                                        kernel_size = 1,\n",
    "                                        stride = 2,\n",
    "                                        padding = 1))\n",
    "                \n",
    "\n",
    "\n",
    "        # ups\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(\n",
    "                in_channels = feature * 2,\n",
    "                out_channels = feature, \n",
    "                kernel_size = 2, stride = 2))\n",
    "            self.ups.append(BottleNeck_Long(in_channels = feature * 2, \n",
    "                                       out_channels = feature))\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # print(self.downs)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        skip_connections=[]\n",
    "        print(\"Encoder\")\n",
    "        x = self.warmup_conv(x)\n",
    "        print(x.shape)\n",
    "\n",
    "    \n",
    "        for i in range(0, len(self.downs)):\n",
    "            x = self.downs[i](x)\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                skip_connections.append(x)\n",
    "                print(\"Involution Block:\", x.shape)\n",
    "            else:\n",
    "                print(\"Downsample:\", x.shape)\n",
    "\n",
    "\n",
    "            \n",
    "        x = self.bottle_neck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        print(f\"After Bottleneck: \", x.shape)\n",
    "\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "\n",
    "            x = self.ups[i](x)\n",
    "            print(f\"Upsample: \", x.shape)\n",
    "            skip_connection = skip_connections[i//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, skip_connection.shape[2::], antialias=True)\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection,x),dim=1)\n",
    "            x = self.ups[i+1](concat_skip)\n",
    "            print(f\"Involution Block: \", x.shape)\n",
    "\n",
    "        return self.final_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 256, 256])\n",
      "Involution Block: torch.Size([1, 32, 256, 256])\n",
      "Downsample: torch.Size([1, 64, 129, 129])\n",
      "Involution Block: torch.Size([1, 64, 129, 129])\n",
      "Downsample: torch.Size([1, 128, 66, 66])\n",
      "Involution Block: torch.Size([1, 128, 66, 66])\n",
      "Downsample: torch.Size([1, 256, 34, 34])\n",
      "Involution Block: torch.Size([1, 256, 34, 34])\n",
      "After Bottleneck:  torch.Size([1, 512, 34, 34])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.3114, -0.1726, -0.0837,  ..., -0.2129,  0.6130,  0.2561],\n",
       "          [ 0.1200,  0.4699, -0.3126,  ...,  0.0853, -0.1210, -0.2007],\n",
       "          [ 0.4664, -0.3636,  0.1720,  ..., -0.1691,  0.3157, -0.1408],\n",
       "          ...,\n",
       "          [ 0.0162, -0.3941, -0.0520,  ..., -0.3603, -0.2271, -0.6019],\n",
       "          [-0.2806, -0.8263, -0.5221,  ...,  0.0626, -0.1143, -0.6053],\n",
       "          [ 0.3929,  0.3507,  0.5398,  ..., -0.9595, -0.4424,  0.4979]],\n",
       "\n",
       "         [[-0.3466, -0.6634, -0.6091,  ...,  0.7380, -0.6423, -0.5715],\n",
       "          [-0.8005, -1.0138, -0.8860,  ..., -0.3679, -0.1191, -0.0067],\n",
       "          [-0.4197,  0.2794, -0.2652,  ..., -0.0132,  0.2775, -0.4289],\n",
       "          ...,\n",
       "          [-0.5381, -0.8163, -0.2908,  ..., -0.4168, -0.2932, -0.1758],\n",
       "          [ 0.0974, -0.3481,  0.2250,  ..., -0.4825, -0.5164,  0.2487],\n",
       "          [-0.2580, -0.2641, -0.2939,  ...,  0.2769,  0.4559, -0.3663]],\n",
       "\n",
       "         [[ 0.5749, -0.6137,  0.0210,  ..., -0.5880,  0.1212, -0.2306],\n",
       "          [-0.1594,  0.3680,  0.3114,  ...,  0.0566, -0.0787,  0.6845],\n",
       "          [-0.4302, -0.6635, -0.0416,  ..., -0.3426, -0.3572,  0.0746],\n",
       "          ...,\n",
       "          [ 0.8980,  0.4101,  0.5250,  ...,  0.0761,  0.1179, -0.1673],\n",
       "          [ 0.4420, -0.4669,  0.2373,  ...,  0.5225,  0.4430,  0.0624],\n",
       "          [ 0.0531,  0.1144, -0.5235,  ..., -0.3337,  0.0571,  0.8186]]]],\n",
       "       device='cuda:0', grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet_long = UNET_Long(in_channels = 3, out_channels = 3,\n",
    "                      features = [32, 64, 128, 256], device = device)\n",
    "\n",
    "unet_long.to(device)\n",
    "\n",
    "# print(unet_long)\n",
    "x = torch.randn(1, 3, 256, 256).to(device)\n",
    "unet_long(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
